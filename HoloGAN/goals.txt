TITLE: HoloGAN: Unsupervised Learning of 3D Representation From Natural Images
URL: https://arxiv.org/abs/1904.01326

OUR MINIMUM GOALS:

QUALITATIVE EVALUATION: Figure 4. For the Chairs dataset with high intra-class variation,
HoloGAN can still disentangle pose (360° azimuth, 160° elevation) and identity.

QUANTITATIVE EVALUATION: Table 1. The HoloGAN result just for the Chairs dataset. (Row:4-Col:2)
Table 1. KID between real images and images generated by HoloGAN and other 2D-based GANs (lower
is better). The table shows that HoloGAN can achieve a competitive or higher KID score with other
methods, while providing explicit control of objects in the generated images (not measured by KID).

NOTE: We have not been able to reach the Chairs dataset yet. But we sent a request. In the worst
case, we plan to just switch the dataset with the CelebA for the same evaluation (Figure 5 and
Table 1 again). We do not prefer the CelebA dataset directly because the authors made some
preprocessing on this dataset and do not explain the preprocess exactly.

—— version 1 submission ——
We reached and downloaded the Chairs dataset but it was closed-box (i.e. including all types of
furniture). Extracting only chairs looks more complicated than using directly the CelebA dataset.
Thus, we found the CelebA dataset more accessible and switched it.

This change does not affect our goals as much (just instead of Figure-4, we plan to generates the
samples given in the Figure-5) because both the both datasets are evaluated with the same
configuration. As we mentioned, the preprocessing steps are not explained in the paper. However,
we found the steps in their GitHub repo as their Tensorflow code. We followed these preprocessing
steps in our implementation. The processed input images used in their code and our project are
compared. We have seen and confirmed that both are the same.

Our samples and KID scores (specified in our goals) can be found in the main.ipynb. As seen from
there, our results are not as successful as theirs. Probably, our code has some bugs. We are still
working on these issues. Our future plan is to test our code more to find bugs. Because our 3D
transformation looks correct, we think that the problem may happen in z values of the generator.
We will test it more delicately. More detail can be found in our Jupyter notebook.

 —— version 2 submission ——
 As we mentioned above, we used the CelebA dataset instead of the Chairs dataset in our experiments.
 But, our qualitative and quantitative goals are valid for both dataset so that we didn't change our
 goals.

 We have been able to reproduce the results that we have aimed to reproduce. The qualitative results
 are very close to Figure 4 in the paper. However, our quantitative goal, KID score, is a little bit
 poorer than the original study.

 More details can be found in the main notebook of the project.
