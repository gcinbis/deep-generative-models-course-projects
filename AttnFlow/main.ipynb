{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENG796 - Project Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes working example of our implementation of Generative Flows with Invertible Attentions, and detailed info about the paper and relevant details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Paper Abstract\n",
    "Flow-based generative models have shown an excellent\n",
    "ability to explicitly learn the probability density function\n",
    "of data via a sequence of invertible transformations. Yet,\n",
    "learning attentions in generative flows remains understudied, while it has made breakthroughs in other domains. To\n",
    "fill the gap, this paper introduces two types of invertible attention mechanisms, i.e., map-based and transformer-based\n",
    "attentions, for both unconditional and conditional generative flows. The key idea is to exploit a masked scheme of\n",
    "these two attentions to learn long-range data dependencies\n",
    "in the context of generative flows. The masked scheme allows for invertible attention modules with tractable Jacobian determinants, enabling its seamless integration at any\n",
    "positions of the flow-based models. The proposed attention\n",
    "mechanisms lead to more efficient generative flows, due to\n",
    "their capability of modeling the long-term data dependencies. Evaluation on multiple image synthesis tasks shows\n",
    "that the proposed attention flows result in efficient models\n",
    "and compare favorably against the state-of-the-art unconditional and conditional generative flows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Paper Summary\n",
    "This paper aims to integrate the idea of attention in deep neural networks, to normalizing flow based models in order to enhance the performance of this class of generative models. This paper addresses the challenges, constraints for integrating attention to NF-based models and explains details of two proposed attention mechanisim named iMap and iTrans attention.\n",
    "### Generative Flows\n",
    "In the family of deep generative models there is a class called flow based models which optimizes exact log-likelihood and provides framework to compute probability densities explicitly. It learns computing the probability density function of the given data with sequence of invertible transformations. It starts with a simple distribution (e.g. Multivariate Gaussian), and transforms it to a complex distribution using change of variables formula for probability density functions. In existing normalizing flow based models feasibility of Jacobian determinant computation is considered, hence invertible transformations are choosen to have preferable Jacobian matrix structure. \n",
    "### Attention\n",
    "In neural networks, naive convolutional layers have a problem of missing global dependencies in their inputs. In order to address this problem, attention mechanisms arrised. There are various techniques to impose attention to neural network models. There are two attention mechansims relevant to proposed solutions, map-based attention and transformers. In map based attention spatial attention maps are learned to scale features given by convolutional layers. Transformers integrates scaled dot product attention with its multi-head versions and it is defacto standart in many tasks in natural language processing and achieves very high performance in vision tasks.\n",
    "### IMAP\n",
    "This paper introduces two attention mechanisms named IMAP and ITrans. IMAP stand for map based attention and we implemented it in our project. Map based attention scales feature map with learned attention weights.IMAP is an additional layer, and it is integrated to MARFlow architecture (Multiscale Autoregressive Priors) which is used as a backbone. Output of the attention layer and attention weights are computed using the following formula.\n",
    "\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/h_out.PNG\"></p>\n",
    "\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/weights_imap.PNG\"></p>\n",
    "\n",
    "M is checkerboard mask, and output of G1 is computed with following formula, where M is checkerboard mask propoesd.\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/G1.PNG\"></p>\n",
    "G2 is 1D convolutional layer, G3 applies average pooling to each channel dimensions, and G4 reorganizes (HxW) dimensional attention weights into (HxW)x(HxW) diagonal matrix. G5 corresponds to nonlinear activation functions. The overall computation graph can be seen in the following figure.\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/Computation%20Graph.PNG\"></p>\n",
    "\n",
    "### ITRANS\n",
    "\n",
    "ITrans stand for invertible transformer, and it is the second attention mechanism introduced in this paper. It is based on state of the art model named transformer, The mapping process is formulated as follows,\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/Itrans_out.PNG\"></p>\n",
    "G4 corrseponds to nonlinear activation function, Q, K and V are computed as follows,\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/Itran_Q.PNG\"></p>\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/ITrans_K.PNG\"></p>\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/ITrans_V.PNG\"></p>\n",
    "G2, G3 corresponds to 2D-1x1 invertible convolutions, and G1 corresponds to multiplication with a checkerboard mask M.\n",
    "Modification of the existing architectures and detailed figure for computation can be seen below,\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/Imap_Itrans_figures.PNG\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from flow_modules.misc import ShiftTransform\n",
    "from marscf_main import MarScfFlow, test_model, save_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the hyperparameters\n",
    "data_root = '../cifar_data'\n",
    "dataset_name = \"cifar10\"\n",
    "batch_size = 32\n",
    "\n",
    "L = 3\n",
    "K = 2\n",
    "C = 256\n",
    "\n",
    "epochs = 100\n",
    "#Setting up the transforms for CIFAR10 Dataset\n",
    "coupling_type = \"affine\"\n",
    "setting_id = 'marscf_' + str(dataset_name) + '_' + str(coupling_type) + '_' + str(K) + '_' + str(C)\n",
    "transform_train = transforms.Compose([ \n",
    "    ShiftTransform(3),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1))])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Train/Test DataLoaders\n",
    "image_shape = [32,32,3]\n",
    "trainset = dsets.CIFAR10(root=data_root, train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,drop_last=True,num_workers=2)\n",
    "\n",
    "testset = dsets.CIFAR10(root=data_root, train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False,drop_last=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "mar_scf = MarScfFlow(batch_size, image_shape, coupling_type, L, K, C).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer and scheduler\n",
    "optimizerG = optim.Adam(mar_scf.parameters(),lr=0.0008, weight_decay=0.00001)\n",
    "scheduler = sched.LambdaLR(optimizerG, lambda s: min(1., s / 10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test model in every 5 epocs\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for data in train_bar:\n",
    "        optimizerG.zero_grad()\n",
    "        data_im = data[0]\n",
    "        if torch.cuda.is_available():\n",
    "            data_im = data_im.cuda()\n",
    "        z, nll, _ = mar_scf(data_im, reverse=False)\n",
    "        loss = torch.mean(nll)\n",
    "        loss = loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "        scheduler.step(global_step)\n",
    "        global_step += batch_size\n",
    "\n",
    "        train_bar.set_description('Train NLL (bits/dim) %.2f | Epoch %d -- Iteration ' % (loss.item(),epoch))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "\n",
    "            tqdm.write('Evaluating model .... ')\n",
    "\n",
    "            curr_test_nll = test_model( mar_scf, test_loader, 1)\n",
    "\n",
    "            if not math.isnan(curr_test_nll):\n",
    "                if curr_test_nll < best_test_nll:\n",
    "                    torch.save(mar_scf.state_dict(), os.path.join('./checkpoints/', setting_id + '.pt'))\n",
    "                    best_test_nll = curr_test_nll\n",
    "\n",
    "            tqdm.write('Best Test NLL (bits/dim) at Epoch %d -- %.3f \\n' % (epoch,best_test_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded!\n",
      "Evaluating model on checkpoint .... \n",
      "Test NLL (bits/dim):  4.113\n",
      "filename =  ./samples/marscf_cifar10_affine_2_256.png\n"
     ]
    }
   ],
   "source": [
    "#Sample Generation from best performed checkpoint\n",
    "try:\n",
    "    state_dict = torch.load( os.path.join('./checkpoints/', setting_id +'.pt'))\n",
    "    mar_scf.load_my_state_dict(state_dict)\n",
    "    print('Checkpoint loaded!')\n",
    "except Exception:\n",
    "    print('Error loading checkpoint!')\n",
    "    sys.exit(0)\n",
    "\n",
    "print('Evaluating model on checkpoint .... ')\n",
    "curr_test_nll = test_model( mar_scf, test_loader, 1)\n",
    "print('Test NLL (bits/dim):  %.3f' % curr_test_nll)\n",
    "save_samples( mar_scf, os.path.join('./samples/', setting_id + '.png'), samples=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Quantitative Evaluation\n",
    "\n",
    "Our training loss curve can be seen below:\n",
    "\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/training_curve.png\"></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We focus our attention on the bits/dim results (Section 5 - Table 3) reported on the Cifar10 dataset, where L=3, K=2 and C=256.\n",
    "\n",
    "\n",
    " | Method               | bits/dim | FID |\n",
    "|----------------------|----------|-----|\n",
    "| AttnFlow-iMap        | 3.247    |40.2 |\n",
    "| AttnFlow-iMap (Ours) | 4.113    |231.4|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples Generated in Original Paper\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/original_gen.png\"></p>\n",
    "\n",
    "### Samples Generated in Our Code\n",
    "\n",
    "\n",
    "<p><img src=\"https://raw.githubusercontent.com/egekara55/CENG796IMG/main/img/marscf_cifar10_affine_2_256111(1).png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Challenges Encountered\n",
    " \n",
    "The main challenge we encountered was relevant to the checkerboard mask.\n",
    "Checkerboard implementation details were not clearly stated in the paper.\n",
    "There were misconceptions about the grid size of the checkerboard mask. We investigated \n",
    "relevant models, GLOW, and RealNVP, and used a checkerboard with grid size 1.\n",
    "\n",
    "ITrans optional mask's shape's dimensionality is not the same as the originally proposed \n",
    "checkerboard, in the paper the original dimensionality of the checkerboard was proposed as, (B, C, HxW), but in order to make an elementwise matrix multiplication, attention was proposed as a square matrix, which introduces a conflict. Our ITrans implementation couldn't converge.\n",
    "\n",
    "It was hard to allocate computational resources to train and evaluate our model in\n",
    "a feasible time. We used our personal computer's GPU with 4GB of memory. In order to speed\n",
    "up the implementation process, we trained our prototypes with a dataset of reduced size \n",
    "to ensure the model's correctness. We switched to a larger dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "540aeb15d51b9fcf15853c394195039ee4d1aa7adbbae075a8f945f87bda4a2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
